# AI Services

Artificial Intelligence and Machine Learning workloads running on the cluster.

## Ollama
- **Access**: Internal Service
- **Description**: Backend for running Large Language Models (LLMs) locally.
- **Hardware**: Relies on GPU-enabled nodes for inference.

## Open WebUI
- **URL**: `open-webui.p.zacharie.org`
- **Description**: Comprehensive user interface for interacting with LLMs hosted by Ollama. Supports chat history, multiple models, and more.

## LobeChat
- **Description**: Modern chat interface for LLMs, capable of connecting to the local Ollama instance.
